---
title: 使用SAC(matlab+simulink)强化学习，遇到很神奇的事情
date: 2025-10-22 21:58:35
tags:
  - 强化学习
  - matlab
  - simulink
categories: 
  - Daily
cover: https://telegraph.ttwwjj.ddns-ip.net/file/AgACAgUAAyEGAAShY8_eAAN9aPjlQ31OG_thFAf2xadW4InSAewAAr0LaxtmKMhX_OMnpX1Tk1QBAAMCAAN3AAM2BA.png

---

# 使用SAC(matlab+simulink)强化学习，遇到很神奇的事情

## 1. 问题描述

使用SAC(matlab+simulink)强化学习，遇到很神奇的事情，就是训练过程中，训练的reward会突然出现负值，然后过很久又恢复正值，或者是一直出现最高值，然后再反弹回来。这是什么原因呢？可能是学习参数没写好吧。

这是我最难绷的一次图片，我感觉持续故障时间是最久的
![‘两次谷底’](https://telegraph.ttwwjj.ddns-ip.net/file/AgACAgUAAyEGAAShY8_eAAN-aPjmvLu9A7f-BPJ1XlpknF9h774AAsYLaxtmKMhXIrv0Hf73e_EBAAMCAAN3AAM2BA.png)
## 2. 尝试解决方案

Gemini的看法
```
根据您提供的“强化学习训练监视器”截图，图中的现象**更可能是强化学习训练过程中的常见问题，而不是MATLAB 2025a或Simulink本身的软件错误(Bug)**。

这张图表展示了使用rlSACAgent（软演员-评论家智能体）为微电网（Microgrid）环境训练时的“回合奖励”（Episode Reward）。虽然奖励值突然大幅下降并维持在一条水平线上看起来很奇怪，但这在强化学习中是有可能发生的。

以下是对该现象的详细分析和解释：

### 现象分析

1.  **奖励的突然下降**：在训练图中，我们能看到两个明显的阶段性下降。第一次大约在第600个回合左右，第二次在第1500个回合之后。在这些下降期间，每个回合的奖励都变成了一个恒定的负值。
2.  **智能体的恢复能力**：值得注意的是，在第一次大幅下降后（大约在第750个回合），智能体能够恢复并学习到更好的策略，获得了比之前更高的奖励。这表明训练算法本身仍在运行，而不是软件崩溃。
3.  **训练的不稳定性**：整个训练过程显示出较高的方差（奖励曲线波动剧烈），这在强化学习中很常见。SAC这类算法旨在通过最大化熵来鼓励探索，有时可能会导致策略探索到未知或不好的状态空间区域。

### 可能的原因

这种奖励的突然“崩溃”通常与强化学习的内在挑战有关，而非软件Bug。主要原因可能包括：

*   **灾难性遗忘 (Catastrophic Forgetting)**：神经网络在学习新策略时，可能会突然忘记之前学得好的策略。这会导致智能体的性能急剧下降。
*   **探索与利用的困境**：智能体在探索新的动作时，可能会偶然发现一个“陷阱”区域。在这个区域里，无论采取什么行动都会导致很差的负面奖励。如果智能体没能很快地从中“逃脱”，就会在一段时间内持续获得低奖励。从图中恒定的负奖励来看，很可能是智能体连续触发了某种终止条件或约束，导致被给予了一个固定的惩罚。
*   **环境模型（Simulink）的问题**：您在Simulink中构建的“Microgrid”环境可能存在特定的状态，一旦进入该状态就会导致仿真失败或触发一个巨大的惩罚，从而结束回合。智能体可能学习到一种策略，使其很容易进入这个“死亡状态”。
*   **超参数设置不当**：学习率、折扣因子、目标网络更新频率等超参数的设置对训练的稳定性至关重要。不合适的超参数可能导致训练过程不稳定，出现数值问题，使得策略网络或价值网络的输出变得极端，从而导致性能崩溃。截图中显示的“Episode Q0”值（对初始状态的价值估计）为一个非常大的负数（-5.46e8），这也侧面印证了价值网络可能出现了不稳定的情况。
*   **奖励函数设计**：如果奖励函数设计不当，可能会引导智能体学到一种看似不错但实际上很脆弱的“捷径”策略。当某些条件发生微小变化时，这种策略就会彻底失效。

### 结论与建议

综合来看，您遇到的情况是强化学习训练中一个有待解决的挑战性问题，而不是一个明确的MATLAB软件Bug。虽然不能100%排除特定版本软件问题的可能性，但其行为模式与已知的RL训练现象高度吻合。

为了解决这个问题，您可以尝试以下几个方向：

*   **检查Simulink环境**：分析在奖励骤降的回合中，Simulink模型发生了什么。是否触发了某个断言（assertion）、到达了某个物理极限或者进入了一个不稳定的运行模式？
*   **调整超参数**：尝试降低学习率（Learning Rate），或者调整其他与SAC算法相关的超参数。
*   **优化奖励函数**：重新审视您的奖励函数，确保它能够平滑、稳定地引导智能体学习，避免存在大的奖励悬崖。
*   **数据记录与分析**：使用MATLAB提供的日志功能，记录训练过程中的更详细数据，例如动作（actions）、观测（observations）以及价值网络的内部状态，以便在奖励下降时进行深入分析。
```

怎么看都是软件bug吧

---

## 3.现在的状态

修改了超参数
现在的运行似乎没有明显问题
拭目以待吧

![还没跑完](https://telegraph.ttwwjj.ddns-ip.net/file/AgACAgUAAyEGAAShY8_eAAN_aPjnpysvEtnqPwYGhOkceIq6RJsAAskLaxtmKMhX5-FaT27F2nABAAMCAAN3AAM2BA.png)